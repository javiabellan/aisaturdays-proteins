{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=\"center\">5. Transformer</h1>\n",
    "\n",
    "### [Pytorch Reference](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)\n",
    "\n",
    "\n",
    "<img width=\"500\" src=\"img/bert.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchviz\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numParams(vocab, d_model, d_ff, n_layers):\n",
    "\n",
    "\tparams_emb_mat   = vocab * d_model\n",
    "    \n",
    "\tparams_attention = d_model*d_model*4 + d_model*4 # Q, K, V, O weights & biases\n",
    "\tparams_dense_1   = d_model*d_ff + d_ff\n",
    "\tparams_dense_2   = d_ff*d_model + d_model\n",
    "\tparams_norm_1    = d_model + d_model\n",
    "\tparams_norm_2    = d_model + d_model\n",
    "\tparams_per_layer = params_attention + params_dense_1 + params_dense_2 + params_norm_1 + params_norm_2\n",
    "\tparams_encoder   = params_per_layer * n_layers\n",
    "    \n",
    "\tparams_total     = params_emb_mat + params_encoder\n",
    "    \n",
    "\treturn params_emb_mat, params_encoder, params_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    \"bertSmall\": {\"vocab\":30522, \"d_model\":768,  \"d_ff\":768*4,  \"n_layers\":6},\n",
    "    \"bertBase\":  {\"vocab\":30522, \"d_model\":768,  \"d_ff\":768*4,  \"n_layers\":12},\n",
    "    \"bertLarge\": {\"vocab\":30522, \"d_model\":1024, \"d_ff\":1024*4, \"n_layers\":24},\n",
    "    \"aminSmall\": {\"vocab\":20,    \"d_model\":8,    \"d_ff\":8*4,    \"n_layers\":6},\n",
    "    \"aminBase\":  {\"vocab\":20,    \"d_model\":8,    \"d_ff\":8*4,    \"n_layers\":12},\n",
    "    \"aminLarge\": {\"vocab\":20,    \"d_model\":16,   \"d_ff\":16*4,   \"n_layers\":12},\n",
    "    \"aminxLarge\": {\"vocab\":20,   \"d_model\":16,   \"d_ff\":16*4,   \"n_layers\":16},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>d_model</th>\n",
       "      <th>d_ff</th>\n",
       "      <th>n_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertSmall</th>\n",
       "      <td>30522</td>\n",
       "      <td>768</td>\n",
       "      <td>3072</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertBase</th>\n",
       "      <td>30522</td>\n",
       "      <td>768</td>\n",
       "      <td>3072</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertLarge</th>\n",
       "      <td>30522</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aminSmall</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aminBase</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aminLarge</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aminxLarge</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            vocab  d_model  d_ff  n_layers\n",
       "bertSmall   30522      768  3072         6\n",
       "bertBase    30522      768  3072        12\n",
       "bertLarge   30522     1024  4096        24\n",
       "aminSmall      20        8    32         6\n",
       "aminBase       20        8    32        12\n",
       "aminLarge      20       16    64        12\n",
       "aminxLarge     20       16    64        16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(configurations).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23440896, 85054464, 108495360)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numParams(**configurations[\"bertBase\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>d_model</th>\n",
       "      <th>d_ff</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>Params Emb</th>\n",
       "      <th>Params Enc</th>\n",
       "      <th>Total params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertSmall</th>\n",
       "      <td>30522</td>\n",
       "      <td>768</td>\n",
       "      <td>3072</td>\n",
       "      <td>6</td>\n",
       "      <td>23440896</td>\n",
       "      <td>42527232</td>\n",
       "      <td>65968128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertBase</th>\n",
       "      <td>30522</td>\n",
       "      <td>768</td>\n",
       "      <td>3072</td>\n",
       "      <td>12</td>\n",
       "      <td>23440896</td>\n",
       "      <td>85054464</td>\n",
       "      <td>108495360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertLarge</th>\n",
       "      <td>30522</td>\n",
       "      <td>1024</td>\n",
       "      <td>4096</td>\n",
       "      <td>24</td>\n",
       "      <td>31254528</td>\n",
       "      <td>302309376</td>\n",
       "      <td>333563904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aminSmall</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>160</td>\n",
       "      <td>5232</td>\n",
       "      <td>5392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aminBase</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>160</td>\n",
       "      <td>10464</td>\n",
       "      <td>10624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aminLarge</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>320</td>\n",
       "      <td>39360</td>\n",
       "      <td>39680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aminxLarge</th>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>320</td>\n",
       "      <td>52480</td>\n",
       "      <td>52800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            vocab  d_model  d_ff  n_layers  Params Emb  Params Enc  \\\n",
       "bertSmall   30522      768  3072         6    23440896    42527232   \n",
       "bertBase    30522      768  3072        12    23440896    85054464   \n",
       "bertLarge   30522     1024  4096        24    31254528   302309376   \n",
       "aminSmall      20        8    32         6         160        5232   \n",
       "aminBase       20        8    32        12         160       10464   \n",
       "aminLarge      20       16    64        12         320       39360   \n",
       "aminxLarge     20       16    64        16         320       52480   \n",
       "\n",
       "            Total params  \n",
       "bertSmall       65968128  \n",
       "bertBase       108495360  \n",
       "bertLarge      333563904  \n",
       "aminSmall           5392  \n",
       "aminBase           10624  \n",
       "aminLarge          39680  \n",
       "aminxLarge         52800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Params Emb\"], df[\"Params Enc\"], df[\"Total params\"] = numParams(**df[[\"vocab\", \"d_model\", \"d_ff\", \"n_layers\"]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My pytroch code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab, d_model, nhead, d_ff, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.embeding  = nn.Embedding(vocab, d_model)\n",
    "        layer          = nn.TransformerEncoderLayer(d_model, nhead, d_ff, dropout=.1, activation='relu')\n",
    "        self.trans_enc = nn.TransformerEncoder(layer, n_layers, norm=None)\n",
    "\n",
    "    def forward(self, seq):\n",
    "\n",
    "        seq = self.embeding(seq)\n",
    "        seq = self.trans_enc(seq)\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bertDebug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2b5485f35666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfigurations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bertDebug\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'bertDebug'"
     ]
    }
   ],
   "source": [
    "numParams(**configurations[\"bertDebug\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108495360"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = Transformer(vocab=30522, d_model=768, d_ff=3072, n_layers=12, nhead=12)\n",
    "sum(p.numel() for p in transformer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeding.weight torch.Size([30522, 768])\n",
      "trans_enc.layers.0.self_attn.in_proj_weight torch.Size([2304, 768])\n",
      "trans_enc.layers.0.self_attn.in_proj_bias torch.Size([2304])\n",
      "trans_enc.layers.0.self_attn.out_proj.weight torch.Size([768, 768])\n",
      "trans_enc.layers.0.self_attn.out_proj.bias torch.Size([768])\n",
      "trans_enc.layers.0.linear1.weight torch.Size([3072, 768])\n",
      "trans_enc.layers.0.linear1.bias torch.Size([3072])\n",
      "trans_enc.layers.0.linear2.weight torch.Size([768, 3072])\n",
      "trans_enc.layers.0.linear2.bias torch.Size([768])\n",
      "trans_enc.layers.0.norm1.weight torch.Size([768])\n",
      "trans_enc.layers.0.norm1.bias torch.Size([768])\n",
      "trans_enc.layers.0.norm2.weight torch.Size([768])\n",
      "trans_enc.layers.0.norm2.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in transformer.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30528768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30522 * 768 + \\\n",
    "2304 * 768  + \\\n",
    "2304        + \\\n",
    "768 * 768   + \\\n",
    "768         + \\\n",
    "3072 * 768  + \\\n",
    "3072        + \\\n",
    "768 * 3072  + \\\n",
    "768         + \\\n",
    "768         + \\\n",
    "768         + \\\n",
    "768         + \\\n",
    "768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30528768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embadding_matrix = 30522 * 768\n",
    "\n",
    "params_attention = 768*768*4 + 768*4 # Q, K, V, O weights & biases\n",
    "params_dense_1   = 768*3072 + 3072\n",
    "params_dense_2   = 3072*768 + 768\n",
    "params_norm_1    = 768 + 768\n",
    "params_norm_2    = 768 + 768\n",
    "param_per_layer  = params_attention + params_dense_1 + params_dense_2 + params_norm_1 + params_norm_2\n",
    "\n",
    "embadding_matrix + (param_per_layer * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30528768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numParams(30522, 768, 3072, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2362368"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768*4 * 768  + \\\n",
    "768*4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
